{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  2.0.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "import sys\n",
    "sys.path.append(\"/Users/Lisa/Desktop/Master Thesis/RoofNetXAI/roofnet\")\n",
    "from utils import data as roof\n",
    "import importlib\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam(model, image):\n",
    "    model.eval()\n",
    "\n",
    "    # Define the transformation for the input image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # Preprocess the image\n",
    "    input_image = transform(image).unsqueeze(0)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_image)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    predicted_class = predicted.item()\n",
    "\n",
    "    # Perform the gradient calculation\n",
    "    output[:, predicted_class].backward()\n",
    "\n",
    "    # Get the gradients from the last convolutional layer\n",
    "    gradients = model.get_activations_gradient()\n",
    "\n",
    "    # Global average pooling of gradients\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "\n",
    "    # Get the feature maps from the last convolutional layer\n",
    "    activations = model.get_activations(input_image).detach()\n",
    "\n",
    "    # Weight the feature maps by the gradients\n",
    "    for i in range(activations.shape[1]):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "    # Average the weighted feature maps\n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    heatmap = F.relu(heatmap)\n",
    "\n",
    "    # Normalize the heatmap\n",
    "    heatmap /= torch.max(heatmap)\n",
    "\n",
    "    # Convert the heatmap to a numpy array\n",
    "    heatmap = heatmap.cpu().numpy()\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This helper function sets the .requires_grad attribute of the parameters in the model to False when we are feature extracting. \n",
    "#By default, when we load a pretrained model all of the parameters have .requires_grad=True, which is fine if we are training from scratch or finetuning. \n",
    "#However, if we are feature extracting and only want to compute gradients for the newly initialized layer then we want all of the other parameters to not require gradients. \n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting): # model is a nn.Module, feature_extracting is a boolean\n",
    "    if feature_extracting: \n",
    "        for param in model.parameters(): # model.parameters() is a generator of tensors\n",
    "            param.requires_grad = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
    "    model_ft = models.resnet18(pretrained=use_pretrained) # model_ft is a nn.Module\n",
    "    set_parameter_requires_grad(model_ft, feature_extract) # model_ft is a nn.Module, feature_extract is a boolean\n",
    "    num_ftrs = model_ft.fc.in_features # num_ftrs is an int which is the number of input features for the last layer\n",
    "    model_ft.fc = nn.Sequential(nn.Dropout(0.25),nn.Linear(num_ftrs, num_classes)) #Trying with dropout \n",
    "    input_size = 224 \n",
    "\n",
    "    return model_ft, input_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@405.024] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('anchor.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@405.024] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('positive.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@405.024] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('negative.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = initialize_model(num_classes=128, feature_extract=True)[0]\n",
    "model.load_state_dict(torch.load('TripleLoss Experiment 64 Train Val'))\n",
    "model.eval()\n",
    "\n",
    "# Load the triplet images (anchor, positive, and negative)\n",
    "anchor_image = cv2.imread('anchor.jpg')\n",
    "positive_image = cv2.imread('positive.jpg')\n",
    "negative_image = cv2.imread('negative.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roofxai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8894df8dd8fdbd6c91ecf09b4a5d40bec4e42bef395be83350036acab2607e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
